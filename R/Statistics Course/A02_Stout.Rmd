---
title: "Assignment 2"
output: html_document
---

**[John Stout]**

Note that two asterisks mark bold regions of text. 

Use a series of R code chunks, below, to load in the L11_D02.csv dataset and complete the analysis. You may wish to reference the Lecture 12 slides, which in particular show how to do a planned comparison in R using aov. You may also do this "manually" within R (i.e., calculate the 1-df contrast F term and look up the p-value using 1-pf(Fval, df1, df2)).

The URL is:

http://www.cogneurolab.org/GradStats/L11_D02.csv

This dataset is described here: http://onlinestatbook.com/2/case_studies/leniency.html

A judgment regarding academic misconduct was made in the context of a picture of the perpetrator, who was expressing one of four facial expressions. "Leniency" is the measure, which is proportional to how lenient the judgment was. 

The levels of the smile variable are 1=false smile, 2=felt smile, 3=miserable smile, 4=neutral control.

I'll start you off by loading the data in the following chunk:

```{r}
df1 = read.csv("http://www.cogneurolab.org/GradStats/L11_D02.csv")
```

Remember: If you get stuck, google is your friend

Insert code chunks, and plain text between chunks to answer any questions posed (mark your responses in bold text). Submit your .rmd file only as your response to the assignment.

```{r}
# load libraries
library(ez)
library(ggplot2)
library(dplyr)
```

1. Recode the variable "smile" so that the names of levels of the factors are more descriptive. You can use anything you want (e.g., dplyr). 

```{r}
df1$smile[which(df1$smile == 1)] = 'false smile'
df1$smile[which(df1$smile == 2)] = 'felt smile'
df1$smile[which(df1$smile == 3)] = 'miserable smile'
df1$smile[which(df1$smile == 4)] = 'neutral control'
```

2. Save the data to a csv file. Load the csv in Jamovi or JASP and conduct an ANOVA. You don't have to show me the results of that analysis, just use it to compare against your R results. 

```{r}
write.csv(df1,"A02_data.csv")
```

3. Summarize data by group, minimally outputting minimum, maximum, mean and standard devation of leniency by group.

```{r}
summary_df1=group_by(df1,smile) %>% summarize(min=min(leniency),max=max(leniency),mean=mean(leniency),sd=sd(leniency))
print(summary_df1)
```
  
4. Make a boxplot, split by group. Do you think there is any worry about normality? Outliers?

```{r}
ggplot(df1, aes(y=leniency, x=smile, fill=smile))+geom_boxplot()+theme_minimal()
```

**I already tested for normality using shapiro wilks test which indicated that the data is not normal, so my answer is probably biased. However, looking at the box plots, the 'felt smile' group seems like its mean would be higher than the median since the upper quartile is so much further from the median than the lower quartile, which could indicate non-normality; however, the 'miserable smile' seems like it could be normal. In this situation, I would rely more heavily on a statistical test like shapiro wilks which indicates that there is worry regarding normality... As for the outliers, there are outliers in the 'miserable smile' and 'neutral control' groups. To determine if I should worry about them, I would inspect the data more closely. However, with what I have right now, I would opt to include rather than exclude the data and wouldn't worry about them.**

5. Do a levene's test and describe the result / conclusion (just a sentence below code chunk suffices).

```{r}
library(car)
leveneTest(df1$leniency,df1$smile,center=mean)
```

**The levenes test indicates that the groups share similar variance since the p > 0.05, accepting the null of homogeneity of variances. This data was checked against Jamovi, that's why I used the mean for the center.**

6. Run an ANOVA in R. Summarize results. Compare to Jamovi output.
```{r}
res.aov = aov(leniency~smile,data=df1)
summary(res.aov)
```
Same as Jamovi output for anova

7. Use pairwise.t.test to calculate (a) post-hoc tests with Holm's correction, (b) post-tests with FDR correction.

```{r}
# a) post-hoc tests with Holms correction
pairwise.t.test(df1$leniency, df1$smile, p.adjust.method="holm")
# b) post-test with FDR correction
pairwise.t.test(df1$leniency, df1$smile, p.adjust.method="fdr")
```
8. Write a very brief summary of your findings (based on ANOVA / post-hoc tests, use just Holm's-corrected post-hoc tests).

**To examine whether individuals judged smiling faces with more leniency, we first ran an ANOVA which revealed that a difference existed between the means of the groups. To then determine between which groups the difference(s) lied, we ran a post-hoc pairwise t-test with a holms correction, finding that leniency was greater for false smiles than for the condition with the neutral control face (p = 0.011). We then ran another post-test using the false-discovery rate correction method, again finding that false smiles were higher than neutral control faces (p = 0.011). **

9. Conduct the following orthogonal set of planned comparisons using R:

(false, felt, miserable) vs. neutral
felt vs. (false, miserable)
false vs. miserable

```{r}
c1 = c(-1,-1,-1,3)
c2 = c(-1,2,-1,0)
c3 = c(-1,0,1,0)
df1$smile=as.factor(df1$smile)
contrasts(df1$smile) = cbind(c1,c2,c3)
df1$smile["contrasts"]

# rerun the anova
res.aov = aov(leniency~smile, data=df1)

# have to use confusing "split" function to extract

summary.aov(res.aov, split=list(smile=list("neutral vs. false, felt, and miserable"=1,"felt vs. false and miserable"=2,"false vs. miserable"=3)))

```

10. Describe a different set of orthogonal planned comparisons that you could have used. You don't have to implement these in R.
**I could have also done c1 = c(3,-1, -1, -1) c2 = c(0,2,-1,-1) c3 = c(0,0,1,-1) **

11. What is the relationship between the ANOVA and planned comparisons? That is, what do ANOVA results tell you about a set of planned, orthogonal contrasts?

**While an ANOVA gives us insight into whether there are differences between multiple independent groups (for example in our df1 variable, it tells us if there are differences in the leniency scores based on facial gesture), the set of planned, orthogonal  constrasts, tell us where the differences lie. **

