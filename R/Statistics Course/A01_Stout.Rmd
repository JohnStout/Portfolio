---
title: 'Assignment #1'
output: html_document
author: John Stout
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

## Variable basics
```{r}
# All below variables -- name them yourselves! "Print"" all variables created in this section right after creating them.
# 1. Create a variable with a unique name, by assigning any number to it
  Var1 = 1
  print(Var1)

# 2. Create a new variable with value equal to the last variable times 2.5 
  Var2 = Var1*2.5
  print(Var2)

# 3. Create a variable that is a vector of 6 arbitrary values. Hint: use the c() function
  Var3_a  = c(1,2,3,4,5,6) # this is in order, but figured I'd do so cause the Var5 looks nice
  # Var3_b  = runif(n = 6, min = 1, max = 10) # alternative - floating nums though
  print(Var3_a)

# 4. Create a new variable that is a vector of the numbers 6 to 1 in descending order. Use the seq() function.
  Var4 = c(seq(from = 6, to = 1))
  print(Var4)

# 5. Create a new variable that is the variable in step 3 multiplied by the variable in step 4.
  Var5 = Var3_a*Var4
  print(Var5)
  
```

## Data basics
```{r} 

## I considered this a separate section since it was named differently, so I didn't print


# 6. Make a new variable that is a vector of 100 numbers drawn randomly from the standard normal distribution. Hint: use rnorm().
  #dist_var = c(rnorm(n = 10000))  # make distribution to draw from
  #Var6     = sample(dist_var,100) # draw from distribution
  Var6      = c(rnorm(n = 100))

# 7. Make another variable that is also a vector of 100 numbers drawn (independently) from the standard normal distribution, also using rnorm().
  #Var7   = sample(dist_var, 100)
  Var7 = c(rnorm(n = 100))

# 8. Calculate the correlation of the variables created in steps 6 and 7, and assign it to a new variable. Use cor(). Then output the variable into the statement below using inline R code.
  Var8 = cor.test(Var6,Var7)

# 9. Calculate the p value of the correlation w.r.t. null hypothesis that r=0. Output into the statement below using inline R code (replace [?] with inline R code).

```

The correlation between the variables is `r round(Var8$estimate,digits=3)`, p = `r round(Var8$p.value,digits=3)`

## Data basics #2
```{r} 
# 10. Load the contents of a csv file into a data frame called big5. The URL of the data is http://www.cogneurolab.org/GradStats/Big5.csv  -- use this URL, not a local copy. Note that the original dataset was retrieved from https://openpsychometrics.org/_rawdata/
# NOTE: The data in this file are *tab-delimited*, not comma-delimited. You need to tell read.csv to expect tab as the separator, instead of previous demos that used commas. Tab is represented by "\t".

# tab-delimited version
Var10 = read.csv(
  file="http://www.cogneurolab.org/GradStats/Big5.csv", 
  header=TRUE, sep="\t")

```

```{r}
# note: above segment is separated for easier debugging -- only run above section once unless you mess up the big5 variable. 

# 11. a. Print the first 10 lines using head() note: you need to pass an additional argument to head to specify printing 10 lines.

  # -> I'm not sure if you wanted the first 10 columns or rows, but I assumed that since you mentioned we had to pass an additional argument to 'head', to show first 10 rows of entire data frame. 
  head(Var10,n=10)

#     b. Reassign the first 200 lines (rows) of big5 to big5 -- i.e., the remaining analysis should be conducted only on the first 200 cases 
  big5 = Var10[1:200,]

# 12. The dataset contains responses to questions that are intended to measure separable personilaty factors. For example, the E questions (variables E1, E2, ...) are intended to index extraversion. The N questions are meant to index neuroticism. The even-number responses should be reverse-scored (i.e, the odd questions are coded 1-5 and the higher value indicates greater evidence for extroversion, e.g., but the even questions are the opposite and higher indicates less evidence for extroversion). 
  
  ### -> My notes:
      # E = extraversion
      # N = neuroticism
      # reverse-score (if 1 is low on odd number rows, 1 is high on even numbered rows)
      # this should be corrected for (6-even so that high values indicate)

#     a. Create a new column in your dataframe called E_all, which is the sum of all odd E scores (E1, E3, E5, E7, E9) plus the sume of all reverse-scored even E scores (6 minus E2, 6 minus E4, etc. up to E10), for each participant. Then make a new column called E_avg, which is the average of the 10 E scores.
  
  ## sum of E's
    # create character arrays to index appropriate columns
    names_odd_E  = c("E1","E3","E5","E7","E9")  # chr array of odd
    names_even_E = c("E2","E4","E6","E8","E10") # chr array of even
    
    # Extract even E's and odd E's
    data_odd_E  = big5[,names_odd_E]
    data_even_E = big5[,names_even_E]
    
    # Correct for reverse scoring
    data_even_cor_E = 6-data_even_E
    
    # sum of all odd E scores (E1, E3, etc) + sum of all even E scores (E2, E4, etc)
    # I know this type of storage could be messy if you run it more than once, but I stored this way because storing like 'big5$__' gave me errors when exporting to csv. Specifically, it was creating extra rows in the excel sheet.
    big5[length(big5)+1] = data.frame(rowSums(data_odd_E)+rowSums(data_even_cor_E))
    
    # rename
    names(big5)[length(big5)] = "E_all"     
    
  ## average of E's
    # store averaged data
    big5[length(big5)+1] = data.frame(rowMeans(cbind(data_odd_E,data_even_cor_E)))
    
    # rename
    names(big5)[length(big5)] = "E_avg"  

#     b. Create a new column in your dataframe called N_all, which is just like E_all but calculated from Neuroticism scores (N1, N2, etc.). Keep in mind, again, the even numbers are reverse-scored.Then make a new column called N_avg, which is the average of the 10 N scores.    
  ## sum of N's
    # create character arrays to index appropriate columns
    names_odd_N  = c("N1","N3","N5","N7","N9")  # chr array of odd
    names_even_N = c("N2","N4","N6","N8","N10") # chr array of even
    
    # Extract even N's and odd N's
    data_odd_N  = big5[,names_odd_N]
    data_even_N = big5[,names_even_N]
    
    # Correct for reverse scoring
    data_even_cor_N = 6-data_even_N
    
    # sum of all odd N scores (N1, N3, etc) + sum of all even N scores (N2, N4, etc)
    big5[length(big5)+1] = data.frame(rowSums(data_odd_N)+rowSums(data_even_cor_N))
    
    # rename
    names(big5)[length(big5)] = "N_all"     
    
  ## average of N's
    big5[length(big5)+1] = data.frame(rowMeans(cbind(data_odd_N,data_even_cor_N)))
    names(big5)[length(big5)] = "N_avg"      
      
#     c. Save this new expanded data frame out as a .csv file called big5.csv, for step #16. Hint: what's the opposite of read.csv?
    
  # save data as csv file
    write.csv(big5,"big5.csv")

# 13. Calculate the mean and standard deviation of each of these new scores, assign to new variables, and use those variables to insert them in the inline code below as appropriate.
    
  # calculate mean and make dataframe to better visualize
  pop_avg = data.frame("Eavg"=mean(big5$E_avg),"Esum"=mean(big5$E_all),"Navg"=mean(big5$N_avg),"Nsum"=mean(big5$N_all))
  
  # calculate sd and make dataframe to better visualize
  pop_sd = data.frame("Eavg"=sd(big5$E_avg),"Esum"=sd(big5$E_all),"Navg"=sd(big5$N_avg),"Nsum"=sd(big5$N_all))  


# 14. Calculate: the correlation, significance, B_EN, and B_0 treating E_avg as the predicted variable (y) and N_avg as the predictor variable (x). Save these values to new variables and modify below to use inline code to insert them (see below outside code block).
  y1 = data.matrix(big5$E_avg) # predicted
  x1 = data.matrix(big5$N_avg) # predictor
  
  # pearsons correlation
  r_stats = cor.test(x1,y1)
  r_val   = r_stats$estimate # extract r value
  p       = r_stats$p.value   # extract p value
  
  # regression
  lm1  = lm(y1~x1)           # predicted comes first, predictor comes second
  B_0  = lm1$coefficients[1]
  B_NE = lm1$coefficients[2]
  
  # checking work
  #r_mom = cor(x1,y1)  
  #B_xy  = r_mom*sd(y1)/sd(x1)

```

After correcting for reverse-scoring, we took the average and standard deviations (sd) of Extraversion (avg = `r pop_avg$Eavg`; sd = `r pop_sd$Eavg`) and Neuroticism (avg = `r pop_avg$Navg`; sd = `r pop_sd$Navg`) scores, noticing that both distributions share a similar mean, with the sd's overlapping. We also assessed the summed Extraversion and Neuroticism scores, observing the same relationship, but only reported the mean scores since they were identical (albeit divided by 10).

Next, to examine the relationship between extraversion and neuroticism, we first ran a correlation analysis, finding a negative correlation between averaged extraversion and neuroticism scores [r = `r r_val`, p = `r round(p,digits = 3)`]. To then examine the degree to which neuroticism predicts extraversion, we ran a linear regression, finding that as neuroticism changes by one unit, extraversion decreases by -0.5 (beta = `r B_NE`). 

In summary, these results suggest that individuals with lower extraversion have higher neuroticism, while individuals with lower neuroticism have higher extraversion. Taking it a step further, we used a linear regression to show that neuroticism scores were predictive of extraversion scores.

## Plotting
```{r}
# 15. In this area, use ggplot() [don't forget to import the ggplot2 library] to plot E_avg scores against N_avg scores. *****(Modified after your update - JS)*****

#   - add the best-fitting line
#   - add the best-fitting equation to the plot
# The final plot should be appear below in the knitted document.

##
# load in ggplot library
library(tidyverse)

# make equation string - note, I got this from your slides
eq = paste0("y = ", round(B_NE,3), "*x + ", round(B_0,3))

# figure - sorry that this is messy, but I wanted to remove the background and have the equation be the same color as the line
fig1 = ggplot(data=big5, aes(x=data.matrix(big5$E_avg),y=data.matrix(big5$N_avg)))+geom_point()
fig1 + theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
      geom_smooth(method = "lm", se = FALSE)+ggtitle(eq)+ theme(plot.title = element_text(lineheight=.8, color='blue'))

```

## 16. Compare to stats package
Using the file you saved out, conduct the same analysis described above for the Big5 dataset, in either JASP, Jamovi, or SPSS, and upload a file containing your results to Canvas along with this RMD file. Please save your results as PDF or other easily-read document format.







