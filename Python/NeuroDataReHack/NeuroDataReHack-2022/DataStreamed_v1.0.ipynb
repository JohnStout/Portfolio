{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a283cd8-2f42-4344-bf1e-c3c5e6d27767",
   "metadata": {},
   "source": [
    "# NeuroDataReHack 2022 - analysis and work flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64942d6d-32b8-4433-bb3b-5e83281e69d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a21b68-73d7-4176-adb6-bbb69911cf75",
   "metadata": {},
   "source": [
    "- Short term goal: Apply coherence detection on pre-existing dataset (Chung et al )\n",
    "- Long term goal: test whether synchrony is predictive of anatomy, or the other way around.\n",
    "\n",
    "*Make sure to set kernel to ipykernel*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d115c-461f-4cd3-8616-d242de89914e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc6a42-f1c9-49f2-b9f6-f79423e8363e",
   "metadata": {},
   "source": [
    "Import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7863c2c6-5c33-450b-9a19-e3ee4089612e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xarray/backends/cfgrib_.py:29: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import vars and dandi api\n",
    "import pynwb\n",
    "import requests\n",
    "import numpy as np\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pynwb import NWBHDF5IO\n",
    "from nwbwidgets import nwb2widget\n",
    "import os # import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5642b5-deb3-4381-9aae-55323021981c",
   "metadata": {},
   "source": [
    "Ben Dichter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07a2ac0-b3f7-46dc-83ae-82d3bb063c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _search_assets(url, filepath):\n",
    "    response = requests.request(\"GET\", url, headers={\"Accept\": \"application/json\"}).json() \n",
    "    \n",
    "    for asset in response[\"results\"]:\n",
    "        if filepath == asset[\"path\"]:\n",
    "            return asset[\"asset_id\"]\n",
    "    \n",
    "    if response.get(\"next\", None):\n",
    "        return _search_assets(response[\"next\"], filepath)\n",
    "    \n",
    "    raise ValueError(f'path {filepath} not found in dandiset {dandiset_id}.')\n",
    "\n",
    "def get_asset_id(dandiset_id, filepath):\n",
    "    url = f\"https://api.dandiarchive.org/api/dandisets/{dandiset_id}/versions/draft/assets/\"\n",
    "    return _search_assets(url, filepath)\n",
    "\n",
    "def get_s3_url(dandiset_id, filepath):\n",
    "    \"\"\"Get the s3 location for any NWB file on DANDI\"\"\"\n",
    "\n",
    "    asset_id = get_asset_id(dandiset_id, filepath)\n",
    "    url = f\"https://api.dandiarchive.org/api/dandisets/{dandiset_id}/versions/draft/assets/{asset_id}/download/\"\n",
    "    \n",
    "    s3_url = requests.request(url=url, method='head').url\n",
    "    if '?' in s3_url:\n",
    "        return s3_url[:s3_url.index('?')]\n",
    "    return s3_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be23e6c4-4e5c-4cb1-ae91-38e44ca9b3ae",
   "metadata": {},
   "source": [
    "----\n",
    "Get session data given dandiset ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe38178-55af-4560-ab9f-f4734b215945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "#dandiset_id = '000004' # dataset\n",
    "dandiset_id = '000065'\n",
    "\n",
    "# get dataset\n",
    "with DandiAPIClient() as client:\n",
    "    # get dandiset using the ID code\n",
    "    dandiset = client.get_dandiset(dandiset_id,'draft')\n",
    "    \n",
    "    # list splits the \"zipped\" generator file\n",
    "    assets   = list(dandiset.get_assets())\n",
    "    \n",
    "    # list comprehension\n",
    "    rats = {os.path.split(x.path)[0] for x in assets} # list comprehension, for loop, {} if unique\n",
    "\n",
    "    # actually just work with sessions for now and call it a day\n",
    "    sessions = [x.path for x in assets]\n",
    "    #print(sessions)\n",
    "\n",
    "    #asset = client.get_dandiset(dandiset_id, 'draft').get_asset_by_path(filepath)\n",
    "    #s3_url = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "\n",
    "# temporarily (I mean before actual data analysis), get one session to get streaming working\n",
    "tempAssetID = sessions[0]\n",
    "asset_id = get_asset_id(dandiset_id, tempAssetID) # this is the URL for download\n",
    "s3_path  = get_s3_url(dandiset_id, tempAssetID) # this is the path to streaming\n",
    "#print(asset_id)\n",
    "\n",
    "# use the \"Read Only S3\" (ros3) driver to stream data directly from DANDI (or any other S3 location)\n",
    "io = NWBHDF5IO(s3_path, mode='r', load_namespaces=True, driver='ros3')\n",
    "\n",
    "nwb = io.read()\n",
    "\n",
    "# this is the golden function here -- Not really working for some reason\n",
    "widgetOut = 1\n",
    "if widgetOut==1:\n",
    "    nwb2widget(nwb)\n",
    "\n",
    "#Get the fields within the NWB file\n",
    "nwbFields = nwb.fields\n",
    "#print(nwbFields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b9186-f542-4c51-9635-ad503ae1f630",
   "metadata": {
    "tags": []
   },
   "source": [
    "If working with dataset 004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc2c86-637f-4dd8-9f7f-16f88a1eba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dandiset_id == '000004':\n",
    "    ##Plot the Waveforms from the NWB file\n",
    "\n",
    "    #Which channel_index to plot? \n",
    "    channel_index = [0]\n",
    "\n",
    "    # get Waveform Means from the NWB file\n",
    "    allwaveformLearn = np.asarray(nwb.units['waveform_mean_encoding'].data)\n",
    "    allwaveformRecog = np.asarray(nwb.units['waveform_mean_recognition'].data)\n",
    "\n",
    "    print(nwb.units)\n",
    "\n",
    "    # Choose Which Channel Index to Plot\n",
    "    waveformLearn = allwaveformLearn[channel_index, :][0]\n",
    "    waveformRecog = allwaveformLearn[channel_index, :][0]\n",
    "\n",
    "    #get brain Areas\n",
    "    brainAreas = np.asarray(nwb.electrodes['location'].data)\n",
    "\n",
    "\n",
    "    #Plot the mean waveforms\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (15, 10)) \n",
    "\n",
    "    #Plot Learning\n",
    "    axes[0].plot(range(len(waveformLearn)), waveformLearn, color = 'blue', marker = 'o', linestyle='dashed',\n",
    "                linewidth=1, markersize=3)\n",
    "    axes[0].set_title('Learning, session: {}, brain Area: {}'.format(nwb.identifier, brainAreas[channel_index][0]))\n",
    "    axes[0].set_xlabel('time (in ms)')\n",
    "    axes[0].set_ylabel('\\u03BCV')\n",
    "\n",
    "    #Plot Recog\n",
    "    axes[1].plot(range(len(waveformRecog)), waveformRecog, color = 'green', marker = 'o', linestyle='dashed',\n",
    "                linewidth=1, markersize=3)\n",
    "    axes[1].set_title('Recognition, session: {}, brain Area: {}'.format(nwb.identifier, brainAreas[channel_index][0]))\n",
    "    axes[1].set_xlabel('time (in ms)')\n",
    "    axes[1].set_ylabel('\\u03BCV')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
